如何使用：

程序实现了对于 contentType、field 和 position 三种分类的分类器。这三者的实现方式是非常类似的，能做的事情也一样。

对于每一种分类器，目前可以实现的任务有两类，即：
 - 训练模型
 - 通过已经训练好的模型来进行分类。

以 field 为例介绍它们的调用方法。



1. 训练模型

文件 field_train_task.py 演示了模型训练的调用方法。所有方法集成在一个类 FieldTrain 中。

首先创建一个类的对象：
 - a = FieldTrain()

这里 FieldTrain() 内可以传入一个参数，用来指定训练输出的根文件夹。比如传入参数 model_dir，则训练的结果将保存在下列文件夹下：
 - model_dir/field/

而并不是直接保存在 model_dir 文件夹下。

为了训练模型，需要从服务器上请求数据。因此，首先要建立与服务器的连接。因此，这里给出连接服务器的配置参数 (示例)：
 - a.connect({'host': '127.0.0.1', 'user': 'user', 'passwd': 'passwd', 'db': 'db'})

程序将自动与服务器建立连接并立即断开，然后返回是否成功连接的信息，与错误原因。

如果能够与服务器建立连接，则下一步可以选择训练算法 (不些就是默认)。下面的代码指定使用 libsvm 库进行训练 (默认算法为 l1dcd)：
 - a.algorithm('libsvm')

LIBSVM 是一个在 linux 上十分易于安装的 SVM 计算库 (具体安装方法详见 LIBSVM 官方文档)，可以选择几种卷积核。除了这个库函数以外，还提供了下列算法：
 - 'admm': 交替方向乘子法 (Alternating Direction Method of Multipliers)，训练 SVM + l1-penalty 的原函数。
 - 'dcd': 对偶坐标梯度下降法 (Dual Coordinate Descent)，训练 SVM 的对偶函数。
 - 'l1dcd': 对偶坐标梯度下降法 (Dual Coordinate Descent)，训练 SVM + l1-penalty 的对偶函数。

对于每一种算法，都会保存这种算法生成的模型。如果字符串没有给这四种的任意一种，程序将返回信息，告知算法不可用。

选择算法之后，还可以选择并行运算的线程数 (不写也是默认)，比如设置 4 线程同时训练 (默认为 4)：
 - a.thread(4)

由于不同的 label 都是单独训练，因此非常容易并行。

设置好参数之后，就可以进行训练：
 - a.train()

程序将自动从服务器上获取数据，然后由文本生成相应的字典，然后生成可供训练的浮点数数组，最后采用上面设置的模型进行训练。

训练过程中将会不断 print 信息。最后会给出训练模型在训练集和测试集上的准确度。训练结果将会保存在对象的私有成员中。

如果之前已经读取过数据，程序将会避免再读一次，同时也不会生成新的字典。

训练结束后，可以选择将 model 保存下来：
 - a.save()

需要注意的是，如果还未训练，则调用该函数将 print 出错误信息。同时，用 algorithm 更换算法将视为回到未训练状态。

训练结束之后还可以查看训练对于每一个 Label 的效果，可以用下列代码画图查看
 - a.plot()

目前提供的功能就有这些，下一步需要提供修改训练参数的接口。



2. 用已有的模型分类

文件 field_train_task.py 演示了分类器可以实现的功能。

首先创建一个类的对象：
 - a = FieldClass()

创建的时候也可以传递一个路径参数进去，表示模型保存的路径在哪里。注意到，如果传入的是 model_dir，则程序将会在下面的路径下去找模型：
 - model_dir/field/

然后选择模型，也就是选择算法：
 - a.algorithm('l1dcd')

然后用分类器进行实现：
 - b = a.classify(articlesstr)

分类器会自动加载字典、自动加载模型、自动将文章数据转换为浮点数、自动计算预测结果，最后 print 出结果，并且返回给一个变量。

如果程序发现没有需要的字典、模型，程序将给出相应错误信息以后停止掉。

目前分类器的功能就这么一些，后续可能还会加入新功能。



3. 模型参数设置

目前还没有实现修改参数的接口，并且 LIBSVM 的参数还没有调好。

调用 LIBSVM 需要在自己的机器上先安装好这个库。

训练速度上，LIBSVM 明显快于 DCD/L1DCD，而 ADMM 是最慢的。同时，LIBSVM 需要占用的内存最小，ADMM 最大，DCD/L1DCD 居中。就算法而言，LIBSVM 全面优势。
